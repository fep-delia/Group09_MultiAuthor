{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39907ac4",
   "metadata": {},
   "source": [
    "# For creating predictions for various fine-tuning configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cef3c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from collections import defaultdict\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "721a7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_align_model(model, input_folders, output_dir, tokenizer, max_length=128):\n",
    "    \"\"\"\n",
    "    Predict sentence-pair changes and align with truth files.\n",
    "\n",
    "    input_folders: dict of difficulty/language -> folder path, e.g.,\n",
    "        {\"easy\": \"Data/easy/validation\", \"DANISH: \"Data/reddit_new_DANISH\", ...}\n",
    "    output_dir: root folder for JSON predictions\n",
    "    model: trained model\n",
    "    tokenizer: tokenizer\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for diff, folder in input_folders.items():\n",
    "        diff_dir = os.path.join(output_dir, diff)\n",
    "        os.makedirs(diff_dir, exist_ok=True)\n",
    "\n",
    "        txt_files = sorted([f for f in os.listdir(folder) if f.endswith(\".txt\")])\n",
    "        for fname in txt_files:\n",
    "            problem_id = fname[:-4]  # e.g., 'problem-1'\n",
    "\n",
    "            # Load sentences\n",
    "            with open(os.path.join(folder, fname), \"r\", encoding=\"utf8\") as f:\n",
    "                sentences = [s.strip() for s in f.readlines() if s.strip()]\n",
    "\n",
    "            # Load truth\n",
    "            truth_path = os.path.join(folder, f\"truth-{problem_id}.json\")\n",
    "            with open(truth_path, \"r\", encoding=\"utf8\") as f:\n",
    "                truth = json.load(f)\n",
    "            num_changes = len(truth[\"changes\"])\n",
    "\n",
    "            # Build sentence pairs\n",
    "            pair_texts = [(sentences[i], sentences[i+1]) for i in range(len(sentences)-1)]\n",
    "\n",
    "            # Tokenize\n",
    "            encodings = tokenizer(\n",
    "                [p[0] for p in pair_texts],\n",
    "                [p[1] for p in pair_texts],\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            # Predict\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**encodings)\n",
    "                preds = torch.argmax(outputs.logits, dim=-1).cpu().tolist()\n",
    "\n",
    "            # Align predictions to truth length\n",
    "            if len(preds) > num_changes:\n",
    "                preds = preds[:num_changes]\n",
    "            elif len(preds) < num_changes:\n",
    "                preds += [0] * (num_changes - len(preds))  # pad with 0\n",
    "\n",
    "            # Build prediction JSON\n",
    "            pred_json = {\n",
    "                \"authors\": truth.get(\"authors\", 0),\n",
    "                \"changes\": preds\n",
    "            }\n",
    "\n",
    "            # Save\n",
    "            out_file = os.path.join(diff_dir, f\"solution-{problem_id}.json\")\n",
    "            with open(out_file, \"w\") as f:\n",
    "                json.dump(pred_json, f)\n",
    "\n",
    "    print(f\"Predictions written to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c03d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/mmBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jhu-clsp/mmBERT-base\", use_fast=True)\n",
    "input_folders = {\n",
    "    \"easy\": \"Data/easy/validation\",\n",
    "    \"medium\": \"Data/medium/validation\",\n",
    "    \"hard\": \"Data/hard/validation\"\n",
    "}\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"jhu-clsp/mmBERT-base\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c83b9",
   "metadata": {},
   "source": [
    "## Prediction generation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b0b57",
   "metadata": {},
   "source": [
    "### Baseline Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a265a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jhu-clsp/mmBERT-base\"\n",
    "\n",
    "#Load the model only; no tokenizer needed\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_base\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bec01",
   "metadata": {},
   "source": [
    "### LoRA Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1546ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"jhu-clsp/mmBERT-base\") \n",
    "model = PeftModel.from_pretrained(base_model, \"trained_adapters/mmbert_lora_mawsa_adapters\")  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_lora\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb13f70",
   "metadata": {},
   "source": [
    "### LoRA 2LCLS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"jhu-clsp/mmBERT-base\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Apply same 2 layer classifier as used for training\n",
    "hidden = base_model.config.hidden_size\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    \"trained_adapters/mmbert_lora_mawsa_adapters_2layercls\"\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_lora_2lcls\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a28c8",
   "metadata": {},
   "source": [
    "### QLoRA Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"jhu-clsp/mmBERT-base\") \n",
    "model = PeftModel.from_pretrained(base_model, \"trained_adapters/mmbert_Qlora_mawsa_adapters\")  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_Qlora\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e7759",
   "metadata": {},
   "source": [
    "### QLoRA 2LCLS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"jhu-clsp/mmBERT-base\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Apply same 2 layer classifier as used for training\n",
    "hidden = base_model.config.hidden_size\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    \"trained_adapters/mmbert_Qlora_mawsa_adapters_2layercls\"\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_Qlora_2layercls\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5b8da",
   "metadata": {},
   "source": [
    "### QLoRA + Language adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ac34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"jhu-clsp/mmBERT-base\") \n",
    "model = PeftModel.from_pretrained(base_model, \"trained_adapters/Qlora_lang_mawsa\")  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_Qlora\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01085f2",
   "metadata": {},
   "source": [
    "## Multilingual predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c328a",
   "metadata": {},
   "source": [
    "New input folders (scraped language specific reddit data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = {\n",
    "    \"DANISH\": \"Data/reddit_dataset_new_DANISH\",\n",
    "    \"ENGLISH\": \"Data/reddit_dataset_new_ENGLISH\",\n",
    "    \"ITALIAN\": \"Data/reddit_dataset_new_ITALIAN\",\n",
    "    \"POLISH\": \"Data/reddit_dataset_new_POLISH\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06c2d0",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jhu-clsp/mmBERT-base\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/multilingual_predictions_base\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbc4b9",
   "metadata": {},
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"jhu-clsp/mmBERT-base\",\n",
    "        use_fast=True\n",
    "    )\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"jhu-clsp/mmBERT-base\") \n",
    "model = PeftModel.from_pretrained(base_model, \"trained_adapters/mmbert_lora_mawsa_adapters\")  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/multilingual_predictions_lora\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e8032",
   "metadata": {},
   "source": [
    "### LoRA 2LCLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"jhu-clsp/mmBERT-base\",\n",
    "        use_fast=True\n",
    "    )\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"jhu-clsp/mmBERT-base\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Apply same 2 layer classifier as used for training\n",
    "hidden = base_model.config.hidden_size\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    \"trained_adapters/mmbert_lora_mawsa_adapters_2layercls\"\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/multilingual_predictions_lora_2lcls\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e674c5",
   "metadata": {},
   "source": [
    "### QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"jhu-clsp/mmBERT-base\",\n",
    "        use_fast=True\n",
    "    )\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"jhu-clsp/mmBERT-base\") \n",
    "model = PeftModel.from_pretrained(base_model, \"trained_adapters/mmbert_Qlora_mawsa_adapters\")  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/multilingual_predictions_Qlora\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5006983e",
   "metadata": {},
   "source": [
    "### QLoRa 2LCLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"jhu-clsp/mmBERT-base\",\n",
    "        use_fast=True\n",
    "    )\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"jhu-clsp/mmBERT-base\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Apply same 2 layer classifier as used for training\n",
    "hidden = base_model.config.hidden_size\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    \"trained_adapters/mmbert_Qlora_mawsa_adapters_2layercls\"\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/mutlilingual_predictions_Qlora_2layercls\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a04ccd",
   "metadata": {},
   "source": [
    "## Language Adapter setup LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMaskedLM,\n",
    "    ModernBertForSequenceClassification\n",
    ")\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "def load_model_for_language(lang_adapter_path, task_adapter_path, device):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"jhu-clsp/mmBERT-base\",\n",
    "        use_fast=True\n",
    "    )\n",
    "\n",
    "    # Load MLM base\n",
    "    mlm_model = AutoModelForMaskedLM.from_pretrained(\n",
    "        \"jhu-clsp/mmBERT-base\"\n",
    "    )\n",
    "\n",
    "    # Load LANGUAGE adapter on MLM\n",
    "    mlm_model = PeftModel.from_pretrained(\n",
    "        mlm_model,\n",
    "        lang_adapter_path,\n",
    "        is_trainable=False\n",
    "    )\n",
    "\n",
    "    # Create classification model\n",
    "    cls_model = ModernBertForSequenceClassification.from_pretrained(\n",
    "        \"jhu-clsp/mmBERT-base\",\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "    # Transplant encoder (this carries language LoRA implicitly)\n",
    "    cls_model.modernbert = mlm_model.base_model.model\n",
    "\n",
    "    # Load TASK adapter ONLY\n",
    "    cls_model = PeftModel.from_pretrained(\n",
    "        cls_model,\n",
    "        task_adapter_path,\n",
    "        is_trainable=False\n",
    "    )\n",
    "\n",
    "    cls_model.to(device)\n",
    "    cls_model.eval()\n",
    "\n",
    "    return cls_model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_adapters = {\n",
    "    \"DANISH\": \"trained_adapters/language_adapters/language_lora_danish\",\n",
    "    \"ENGLISH\": \"trained_adapters/language_adapters/language_lora_english\",\n",
    "    \"ITALIAN\": \"trained_adapters/language_adapters/language_lora_italian\",\n",
    "    \"POLISH\": \"trained_adapters/language_adapters/language_lora_polish\"\n",
    "}\n",
    "\n",
    "task_adapter = \"trained_adapters/mmbert_Qlora_lang_mawsa_adapters_peft\"\n",
    "\n",
    "for lang, lang_adapter_path in language_adapters.items():\n",
    "    model, tokenizer = load_model_for_language(\n",
    "        lang_adapter_path,\n",
    "        task_adapter,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    predict_align_model(\n",
    "        model=model,\n",
    "        input_folders={lang: f\"Data/reddit_dataset_new_{lang}\"},\n",
    "        output_dir=f\"predictions/LoRA_language_adapter_predictions\",\n",
    "        tokenizer=tokenizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_lora_lang\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6934c29b",
   "metadata": {},
   "source": [
    "### QLoRA_2LCLS + English Lang_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"jhu-clsp/mmBERT-base\",\n",
    "    num_labels=2,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "hidden = base_model.config.hidden_size\n",
    "base_model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    \"trained_adapters/mmbert_Qlora_lang_mawsa_adapters_2layercls\"\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_folders,\n",
    "    output_dir=\"predictions/predictions_Qlora_lang\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbf110",
   "metadata": {},
   "source": [
    "## Parallel Bottleneck Adapter Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfee5d",
   "metadata": {},
   "source": [
    "### Adapter loading and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83716644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/mmBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Model class 'ModernBertForMaskedLM' of found prediction head does not match current model class.\n",
      "Model class 'ModernBertForMaskedLM' of found prediction head does not match current model class.\n",
      "Model class 'ModernBertForMaskedLM' of found prediction head does not match current model class.\n",
      "Model class 'ModernBertForMaskedLM' of found prediction head does not match current model class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "english_adapter          bottleneck        1,936,032       0.631       0       1\n",
      "danish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "italian_adapter          bottleneck        1,936,032       0.631       0       1\n",
      "polish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "task                     bottleneck        1,639,968       0.534       0       1\n",
      "task_2lcls               bottleneck        1,639,968       0.534       0       1\n",
      "task_lang                bottleneck        1,639,968       0.534       0       1\n",
      "task_lang_2lcls          bottleneck        1,639,968       0.534       0       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               306,939,648     100.000               1\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jhu-clsp/mmBERT-base\", use_fast=True)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import adapters\n",
    "from adapters import AdapterModelInterface, SeqBnInvConfig\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load base model\n",
    "from adapters import AutoAdapterModel\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"jhu-clsp/mmBERT-base\",\n",
    "    num_labels=2,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "\n",
    "plugin_interface = AdapterModelInterface(\n",
    "    adapter_methods=[\"bottleneck\", \"invertible\"],\n",
    "    model_embeddings=\"embeddings\",\n",
    "    model_layers=\"layers\",\n",
    "    layer_self_attn=\"attn\",\n",
    "    layer_cross_attn=None,\n",
    "    attn_qkv_proj=\"Wqkv\",\n",
    "    attn_o_proj=\"Wo\",\n",
    "    layer_intermediate_proj=\"mlp.Wi\",\n",
    "    layer_output_proj=\"mlp.Wo\",\n",
    "    layer_pre_self_attn=\"attn\",\n",
    "    layer_pre_cross_attn=None,\n",
    "    layer_pre_ffn=\"mlp\",\n",
    "    layer_ln_1=\"mlp_norm\",\n",
    "    layer_ln_2=None,\n",
    ")\n",
    "\n",
    "adapters.init(model, interface=plugin_interface)\n",
    "\n",
    "# loading all trained adapters for use in each evaluation\n",
    "\n",
    "lang_adapter_english = model.load_adapter(\n",
    "    \"trained_adapters/language_adapters/English_adapter_loss_20.47\",\n",
    "    load_as=\"english_adapter\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "lang_adapter_danish = model.load_adapter(\n",
    "    \"trained_adapters/language_adapters/Danish_adapter_loss_14.64\",\n",
    "    load_as=\"danish_adapter\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "lang_adapter_italian = model.load_adapter(\n",
    "    \"trained_adapters/language_adapters/Italian_adapter_loss_14.97\",\n",
    "    load_as=\"italian_adapter\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "lang_adapter_polish = model.load_adapter(\n",
    "    \"trained_adapters/language_adapters/Polish_adapter_loss_12.18\",\n",
    "    load_as=\"polish_adapter\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "task_adapter= model.load_adapter(\n",
    "    \"trained_adapters/mmbert_parallelseqbn\",\n",
    "    load_as=\"task\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "task_adapter_2lcls = model.load_adapter(\n",
    "    \"trained_adapters/mmbert_parallelseqbn_2lcls\",\n",
    "    load_as=\"task_2lcls\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "task_adapter_lang= model.load_adapter(\n",
    "    \"trained_adapters/mmbert_parallelseqbn_lang\",\n",
    "    load_as=\"task_lang\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "task_adapter_lang_2lcls= model.load_adapter(\n",
    "    \"trained_adapters/mmbert_parallelseqbn_lang_2lcls\",\n",
    "    load_as=\"task_lang_2lcls\",\n",
    "    set_active=False\n",
    ")\n",
    "\n",
    "\n",
    "print(model.adapter_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dcb1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pan = {\n",
    "    \"easy\": \"Data/easy/validation\",\n",
    "    \"medium\": \"Data/medium/validation\",\n",
    "    \"hard\": \"Data/hard/validation\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0d50724",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_multilingual = {\n",
    "    \"DANISH\": \"Data/reddit_dataset_new_DANISH\",\n",
    "    \"ENGLISH\": \"Data/reddit_dataset_new_ENGLISH\",\n",
    "    \"ITALIAN\": \"Data/reddit_dataset_new_ITALIAN\",\n",
    "    \"POLISH\": \"Data/reddit_dataset_new_POLISH\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a6396",
   "metadata": {},
   "source": [
    "## Single layer head predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63de265",
   "metadata": {},
   "source": [
    "### ParallelSeqBN Task test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc64a6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/predictions_parallelseqbn\n"
     ]
    }
   ],
   "source": [
    "model.set_active_adapters(None)\n",
    "model.set_active_adapters(\"task\")\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_pan,\n",
    "    output_dir=\"predictions/predictions_parallelseqbn\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993522a",
   "metadata": {},
   "source": [
    "### ParallelSeqBn + English adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44766381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BjÃ¸rn\\AppData\\Roaming\\Python\\Python313\\site-packages\\adapters\\composition.py:243: FutureWarning: Passing list objects for adapter activation is deprecated. Please use Stack or Fuse explicitly.\n",
      "  warnings.warn(\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "english_adapter          bottleneck        1,936,032       0.631       1       1\n",
      "danish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "italian_adapter          bottleneck        1,936,032       0.631       0       1\n",
      "polish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "task                     bottleneck        1,639,968       0.534       0       1\n",
      "task_2lcls               bottleneck        1,639,968       0.534       0       1\n",
      "task_lang                bottleneck        1,639,968       0.534       1       1\n",
      "task_lang_2lcls          bottleneck        1,639,968       0.534       0       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               306,939,648     100.000               1\n",
      "================================================================================\n",
      "Predictions written to predictions/predictions_parallelseqbn_lang\n"
     ]
    }
   ],
   "source": [
    "model.set_active_adapters(None)\n",
    "model.set_active_adapters([\"task_lang\", \"english_adapter\"])\n",
    "print(model.adapter_summary())\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_pan,\n",
    "    output_dir=\"predictions/predictions_parallelseqbn_lang\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631efe3",
   "metadata": {},
   "source": [
    "### Multilingual ParallelSeqBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90c82bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/mutlilingual_predictions_parallelseqbn\n"
     ]
    }
   ],
   "source": [
    "model.set_active_adapters(None)\n",
    "model.set_active_adapters(\"task\")\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_multilingual,\n",
    "    output_dir=\"predictions/mutlilingual_predictions_parallelseqbn\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ce9f5",
   "metadata": {},
   "source": [
    "### Multilingual ParallelSeqBN + language adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217ba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/parallelseqbn_lang_adapter_predictions/DANISH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/parallelseqbn_lang_adapter_predictions/ENGLISH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/parallelseqbn_lang_adapter_predictions/ITALIAN\n",
      "Predictions written to predictions/parallelseqbn_lang_adapter_predictions/POLISH\n"
     ]
    }
   ],
   "source": [
    "language_adapters = {\n",
    "    \"DANISH\": \"danish_adapter\",\n",
    "    \"ENGLISH\": \"english_adapter\",\n",
    "    \"ITALIAN\": \"italian_adapter\",\n",
    "    \"POLISH\": \"polish_adapter\"\n",
    "}\n",
    "\n",
    "for lang, adapter_name in language_adapters.items():\n",
    "    model.set_active_adapters(None)\n",
    "    model.set_active_adapters([adapter_name, \"task_lang\"])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predict_align_model(\n",
    "        model=model,\n",
    "        input_folders={lang: f\"Data/reddit_dataset_new_{lang}\"},\n",
    "        output_dir=f\"predictions/parallelseqbn_lang_adapter_predictions\",\n",
    "        tokenizer=tokenizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7386f",
   "metadata": {},
   "source": [
    "## ParallelSeqBN 2 layer head predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4efc18",
   "metadata": {},
   "source": [
    "### ParallelSeqBn 2lcls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c7e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/predictions_parallelseqbn_2lcls\n"
     ]
    }
   ],
   "source": [
    "model.set_active_adapters(None)\n",
    "model.set_active_adapters(\"task_2lcls\")\n",
    "\n",
    "hidden = model.config.hidden_size\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_pan,\n",
    "    output_dir=\"predictions/predictions_parallelseqbn_2lcls\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922bfa1",
   "metadata": {},
   "source": [
    "### ParallelSeqBn 2lcls + English adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c969c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "english_adapter          bottleneck        1,936,032       0.631       1       1\n",
      "danish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "italian_adapter          bottleneck        1,936,032       0.631       0       1\n",
      "polish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "task                     bottleneck        1,639,968       0.534       0       1\n",
      "task_2lcls               bottleneck        1,639,968       0.534       0       1\n",
      "task_lang                bottleneck        1,639,968       0.534       0       1\n",
      "task_lang_2lcls          bottleneck        1,639,968       0.534       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               306,939,648     100.000               1\n",
      "================================================================================\n",
      "Predictions written to predictions/predictions_parallelseqbn_lang_2lcls\n"
     ]
    }
   ],
   "source": [
    "model.set_active_adapters(None)\n",
    "model.set_active_adapters([\"task_lang_2lcls\", \"english_adapter\"])\n",
    "print(model.adapter_summary())\n",
    "hidden = model.config.hidden_size\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_pan,\n",
    "    output_dir=\"predictions/predictions_parallelseqbn_lang_2lcls\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4106276",
   "metadata": {},
   "source": [
    "### ParallelSeqBn 2lcls multilingual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d63c18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "english_adapter          bottleneck        1,936,032       0.631       1       1\n",
      "danish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "italian_adapter          bottleneck        1,936,032       0.631       0       1\n",
      "polish_adapter           bottleneck        1,936,032       0.631       0       1\n",
      "task                     bottleneck        1,639,968       0.534       0       1\n",
      "task_2lcls               bottleneck        1,639,968       0.534       0       1\n",
      "task_lang                bottleneck        1,639,968       0.534       0       1\n",
      "task_lang_2lcls          bottleneck        1,639,968       0.534       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               306,939,648     100.000               1\n",
      "================================================================================\n",
      "Predictions written to predictions/multilingual_predictions_parallelseqbn_lang_2lcls\n"
     ]
    }
   ],
   "source": [
    "model.set_active_adapters(None)\n",
    "model.set_active_adapters([\"task_lang_2lcls\", \"english_adapter\"])\n",
    "print(model.adapter_summary())\n",
    "hidden = model.config.hidden_size\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predict_align_model(\n",
    "    model=model,\n",
    "    input_folders=input_multilingual,\n",
    "    output_dir=\"predictions/multilingual_predictions_parallelseqbn_lang_2lcls\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a56719",
   "metadata": {},
   "source": [
    "### ParallelSeqBn 2lcls multilingual + language adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa7615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/parallelseqbn_2lcls_lang_adapter_predictions/DANISH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/parallelseqbn_2lcls_lang_adapter_predictions/ENGLISH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions/parallelseqbn_2lcls_lang_adapter_predictions/ITALIAN\n",
      "Predictions written to predictions/parallelseqbn_2lcls_lang_adapter_predictions/POLISH\n"
     ]
    }
   ],
   "source": [
    "language_adapters = {\n",
    "    \"DANISH\": \"danish_adapter\",\n",
    "    \"ENGLISH\": \"english_adapter\",\n",
    "    \"ITALIAN\": \"italian_adapter\",\n",
    "    \"POLISH\": \"polish_adapter\"\n",
    "}\n",
    "\n",
    "hidden = model.config.hidden_size\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden, 2)\n",
    ")\n",
    "\n",
    "\n",
    "for lang, adapter_name in language_adapters.items():\n",
    "    model.set_active_adapters(None)\n",
    "    model.set_active_adapters([adapter_name, \"task_lang_2lcls\"])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predict_align_model(\n",
    "        model=model,\n",
    "        input_folders={lang: f\"Data/reddit_dataset_new_{lang}\"},\n",
    "        output_dir=f\"predictions/parallelseqbn_2lcls_lang_adapter_predictions\",\n",
    "        tokenizer=tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23473e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
