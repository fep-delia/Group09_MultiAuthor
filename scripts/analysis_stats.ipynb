{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86e9a97",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Please make sure to have the necessary data folders placed in the same directory where you place this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "762b592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import csv\n",
    "import html\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Set, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3f684d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "COUNT_STRING_TOKENS_TOO = False\n",
    "PAN_ROOT = Path(\"pan25-multi-author-analysis\")\n",
    "PAN_SAMPLE_N = 250\n",
    "RANDOM_SEED = 42\n",
    "JSON_SAMPLE_MATCH_TXT = False\n",
    "DEBUG_PAN_DISCOVERY = False\n",
    "LEXICON_DIR = Path(\"lexicons_cache\")\n",
    "LEXICON_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# HurtLex URLs (public)- if you are offline, manually download to lexicons_cache/hurtlex_<lang>.tsv\n",
    "HURTLEX_LANG_URLS: Dict[str, str] = {\n",
    "    \"en\": \"https://raw.githubusercontent.com/valeriobasile/hurtlex/master/lexica/EN/1.2/hurtlex_EN.tsv\",\n",
    "    \"it\": \"https://raw.githubusercontent.com/valeriobasile/hurtlex/master/lexica/IT/1.2/hurtlex_IT.tsv\",\n",
    "    \"pl\": \"https://raw.githubusercontent.com/valeriobasile/hurtlex/master/lexica/PL/1.2/hurtlex_PL.tsv\",\n",
    "    \"da\": \"https://raw.githubusercontent.com/valeriobasile/hurtlex/master/lexica/DA/1.2/hurtlex_DA.tsv\",\n",
    "}\n",
    "\n",
    "HURTLEX_RESTRICT_TO_COMMON_TOX_CATEGORIES = True\n",
    "COMMON_TOX_CATS = {\n",
    "    \"ps\",\n",
    "    \"pa\",\n",
    "    \"ddf\",\n",
    "    \"asf\",\n",
    "    \"asm\",\n",
    "    \"isf\",\n",
    "    \"ism\",\n",
    "    \"pr\",\n",
    "    \"or\",\n",
    "    \"om\",\n",
    "    \"re\",\n",
    "    \"sv\",\n",
    "}\n",
    "\n",
    "HURTLEX_LEVELS_ALLOWED: Optional[Set[str]] = {\"conservative\"}\n",
    "_HURTLEX_CACHE: Dict[str, Set[str]] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bdc4d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence splitting helpers   \n",
    "\n",
    "HARD_WRAP_MIN_CHARS = 55\n",
    "\n",
    "def _unescape_basic_html(text: str) -> str:\n",
    "    t = html.unescape(text)\n",
    "    t = t.replace(\"&gt\", \">\").replace(\"&lt\", \"<\").replace(\"&amp\", \"&\")\n",
    "    return t\n",
    "\n",
    "def _strip_leading_quotes(line: str) -> str:\n",
    "    s = line.lstrip()\n",
    "    prefixes = (\">\", \"&gt;\", \"&gt\")\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for pref in prefixes:\n",
    "            if s.startswith(pref):\n",
    "                s = s[len(pref):].lstrip()\n",
    "                changed = True\n",
    "    return s\n",
    "\n",
    "WORD_RE = re.compile(r\"[^\\W_]+(?:[â€™'\\-][^\\W_]+)*\", re.UNICODE)\n",
    "\n",
    "def iter_files(folder: Path, pattern: str, recursive: bool = True) -> Iterable[Path]:\n",
    "    if not folder.exists():\n",
    "        return\n",
    "    if recursive:\n",
    "        yield from folder.rglob(pattern)\n",
    "    else:\n",
    "        yield from folder.glob(pattern)\n",
    "\n",
    "def iter_json_files(folder: Path, recursive: bool = True) -> Iterable[Path]:\n",
    "    if not folder.exists():\n",
    "        return\n",
    "    it = folder.rglob(\"*\") if recursive else folder.glob(\"*\")\n",
    "    for p in it:\n",
    "        if p.is_file() and p.suffix.lower() == \".json\":\n",
    "            yield p\n",
    "\n",
    "def read_text(path: Path) -> str:\n",
    "    try:\n",
    "        return path.read_text(encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "def choose_sample(paths: List[Path], sample_n: Optional[int], rng: random.Random) -> List[Path]:\n",
    "    if sample_n is None or sample_n <= 0 or sample_n >= len(paths):\n",
    "        return paths\n",
    "    return rng.sample(paths, k=sample_n)\n",
    "\n",
    "def list_txt_files(folder: Path) -> List[Path]:\n",
    "    return sorted(iter_files(folder, \"*.txt\", recursive=True))\n",
    "\n",
    "def split_sentences(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    t = _unescape_basic_html(text)\n",
    "    t = t.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    sentences: List[str] = []\n",
    "    for ln in t.split(\"\\n\"):\n",
    "        ln = _strip_leading_quotes(ln)\n",
    "        ln = \" \".join(ln.split())  # collapse whitespace\n",
    "        if not ln:\n",
    "            continue\n",
    "        sentences.append(ln)\n",
    "    return sentences\n",
    "\n",
    "def _tokenize(text: str) -> List[str]:\n",
    "    return [w.lower() for w in WORD_RE.findall(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17a8cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text level statistics\n",
    "\n",
    "def compute_stats_for_text(text: str) -> Tuple[int, int, int, Optional[int], Optional[int]]:\n",
    "    parts = split_sentences(text)\n",
    "    sentence_count = 0\n",
    "    word_count = 0\n",
    "    total_word_chars = 0\n",
    "    min_sentence_len_words: Optional[int] = None\n",
    "    max_sentence_len_words: Optional[int] = None\n",
    "    for sent in parts:\n",
    "        words = WORD_RE.findall(sent)\n",
    "        if not words:\n",
    "            continue\n",
    "        if len(words) == 1 and words[0].lower() in {\"gt\", \"lt\", \"amp\"}:\n",
    "            continue\n",
    "        sentence_count += 1\n",
    "        sent_len = len(words)\n",
    "        word_count += sent_len\n",
    "        total_word_chars += sum(len(w) for w in words)\n",
    "        if min_sentence_len_words is None or sent_len < min_sentence_len_words:\n",
    "            min_sentence_len_words = sent_len\n",
    "        if max_sentence_len_words is None or sent_len > max_sentence_len_words:\n",
    "            max_sentence_len_words = sent_len\n",
    "    return sentence_count, word_count, total_word_chars, min_sentence_len_words, max_sentence_len_words\n",
    "\n",
    "def compute_text_stats_for_paths(txt_paths: List[Path]) -> Dict[str, Optional[float]]:\n",
    "    sentence_count = 0\n",
    "    word_count = 0\n",
    "    total_word_chars = 0\n",
    "    min_sentence_len_words: Optional[int] = None\n",
    "    max_sentence_len_words: Optional[int] = None\n",
    "    min_sentence_len_files: List[str] = []\n",
    "    max_sentence_len_file: Optional[str] = None\n",
    "    sentences_per_doc: List[int] = []\n",
    "    for p in txt_paths:\n",
    "        text = read_text(p)\n",
    "        s_cnt, w_cnt, w_chars, doc_min, doc_max = compute_stats_for_text(text)\n",
    "        sentence_count += s_cnt\n",
    "        word_count += w_cnt\n",
    "        total_word_chars += w_chars\n",
    "        if s_cnt > 0:\n",
    "            sentences_per_doc.append(s_cnt)\n",
    "        if doc_min is not None:\n",
    "            if min_sentence_len_words is None or doc_min < min_sentence_len_words:\n",
    "                min_sentence_len_words = doc_min\n",
    "                min_sentence_len_files = [str(p)]\n",
    "            elif doc_min == min_sentence_len_words:\n",
    "                if str(p) not in min_sentence_len_files and len(min_sentence_len_files) < 2:\n",
    "                    min_sentence_len_files.append(str(p))\n",
    "        if doc_max is not None:\n",
    "            if max_sentence_len_words is None or doc_max > max_sentence_len_words:\n",
    "                max_sentence_len_words = doc_max\n",
    "                max_sentence_len_file = str(p)\n",
    "    avg_sentence_len = (word_count / sentence_count) if sentence_count > 0 else None\n",
    "    avg_word_len = (total_word_chars / word_count) if word_count > 0 else None\n",
    "    min_sentences_per_doc = min(sentences_per_doc) if sentences_per_doc else None\n",
    "    max_sentences_per_doc = max(sentences_per_doc) if sentences_per_doc else None\n",
    "    avg_sentences_per_doc = (sum(sentences_per_doc) / len(sentences_per_doc)) if sentences_per_doc else None\n",
    "    return {\n",
    "        \"txt_files\": len(txt_paths),\n",
    "        \"sentences\": sentence_count,\n",
    "        \"words\": word_count,\n",
    "        \"avg_sentence_len_words\": avg_sentence_len,\n",
    "        \"min_sentence_len_words\": float(min_sentence_len_words) if min_sentence_len_words is not None else None,\n",
    "        \"min_sentence_len_files\": min_sentence_len_files,\n",
    "        \"max_sentence_len_words\": float(max_sentence_len_words) if max_sentence_len_words is not None else None,\n",
    "        \"max_sentence_len_file\": max_sentence_len_file,\n",
    "        \"avg_word_len_chars\": avg_word_len,\n",
    "        \"min_sentences_per_doc\": float(min_sentences_per_doc) if min_sentences_per_doc is not None else None,\n",
    "        \"max_sentences_per_doc\": float(max_sentences_per_doc) if max_sentences_per_doc is not None else None,\n",
    "        \"avg_sentences_per_doc\": avg_sentences_per_doc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "08f021ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informality & register markers:\n",
    "# The informality score used here is a simplistic heuristic based on a limited subset of markers- mainly orthographic ones. \n",
    "# As a result, it provides very incomplete coverage and should be interpreted with caution, just as an additional check.\n",
    "\n",
    "REPEATED_PUNCT_RE = re.compile(r\"([!?])\\1{1,}|[!?]{3,}\")\n",
    "ELONGATION_RE = re.compile(r\"([A-Za-zÃ€-Ã–Ã˜-Ã¶Ã¸-Ã¿])\\1{2,}\", re.UNICODE)\n",
    "ALL_CAPS_TOKEN_RE = re.compile(r\"\\b[A-Z]{2,}\\b\")\n",
    "\n",
    "def compute_informality_for_paths(txt_paths: List[Path]) -> Dict[str, float]:\n",
    "    tokens_total = 0\n",
    "    repeated_punct_total = 0\n",
    "    all_caps_total = 0\n",
    "    elong_total = 0\n",
    "    for p in txt_paths:\n",
    "        text = read_text(p)\n",
    "        toks = _tokenize(text)\n",
    "        if not toks:\n",
    "            continue\n",
    "        tokens_total += len(toks)\n",
    "        repeated_punct_total += len(REPEATED_PUNCT_RE.findall(text))\n",
    "        all_caps_total += len(ALL_CAPS_TOKEN_RE.findall(text))\n",
    "        elong_total += sum(1 for t in toks if ELONGATION_RE.search(t))\n",
    "    if tokens_total == 0:\n",
    "        return {\n",
    "            \"repeated_punct_rate\": 0.0,\n",
    "            \"all_caps_token_rate\": 0.0,\n",
    "            \"elongation_rate\": 0.0,\n",
    "            \"informality_score\": 0.0,\n",
    "        }\n",
    "    per_1k = lambda x: 1000.0 * x / tokens_total\n",
    "    repeated_punct_rate = per_1k(repeated_punct_total)\n",
    "    all_caps_token_rate = per_1k(all_caps_total)\n",
    "    elongation_rate = per_1k(elong_total)\n",
    "    return {\n",
    "        \"repeated_punct_rate\": repeated_punct_rate,\n",
    "        \"all_caps_token_rate\": all_caps_token_rate,\n",
    "        \"elongation_rate\": elongation_rate,\n",
    "        \"informality_score\": repeated_punct_rate + all_caps_token_rate + elongation_rate,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb6d573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toxicity detection: this loads HurtLex corpora and computes:\n",
    "# - toxic tokens total\n",
    "# - toxic tokens per 1k tokens\n",
    "# - % documents with â‰¥1 toxic token\n",
    "\n",
    "def _download(url: str, dest: Path) -> None:\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with urllib.request.urlopen(url) as r:\n",
    "        dest.write_bytes(r.read())\n",
    "\n",
    "def load_hurtlex(lang: str) -> Set[str]:\n",
    "    lang = lang.lower()\n",
    "    if lang in _HURTLEX_CACHE:\n",
    "        return _HURTLEX_CACHE[lang]\n",
    "    cache_path = LEXICON_DIR / f\"hurtlex_{lang}.tsv\"\n",
    "    if not cache_path.exists():\n",
    "        url = HURTLEX_LANG_URLS.get(lang)\n",
    "        if not url:\n",
    "            print(f\"[WARN] No HurtLex URL configured for lang={lang}; toxicity will be 0.\")\n",
    "            _HURTLEX_CACHE[lang] = set()\n",
    "            return _HURTLEX_CACHE[lang]\n",
    "        try:\n",
    "            print(f\"[INFO] Downloading HurtLex {lang} -> {cache_path}\")\n",
    "            _download(url, cache_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to download HurtLex for lang={lang}: {e}. Toxicity will be 0.\")\n",
    "            _HURTLEX_CACHE[lang] = set()\n",
    "            return _HURTLEX_CACHE[lang]\n",
    "    entries: Set[str] = set()\n",
    "    try:\n",
    "        with cache_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\", newline=\"\") as f:\n",
    "            reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                lemma = (row.get(\"lemma\") or row.get(\"term\") or row.get(\"word\") or \"\").strip().lower()\n",
    "                cat = (row.get(\"category\") or row.get(\"cat\") or \"\").strip().lower()\n",
    "\n",
    "                level = (row.get(\"level\") or \"\").strip().lower()\n",
    "                if HURTLEX_LEVELS_ALLOWED and level and level not in HURTLEX_LEVELS_ALLOWED:\n",
    "                    continue\n",
    "                if not lemma:\n",
    "                    continue\n",
    "                if HURTLEX_RESTRICT_TO_COMMON_TOX_CATEGORIES and cat and cat not in COMMON_TOX_CATS:\n",
    "                    continue\n",
    "                entries.add(lemma)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to parse HurtLex file {cache_path}: {e}. Toxicity will be 0.\")\n",
    "        entries = set()\n",
    "    _HURTLEX_CACHE[lang] = entries\n",
    "    return entries\n",
    "\n",
    "def detect_language_for_folder(folder: Path) -> str:\n",
    "    name = folder.name.lower()\n",
    "    if \"polish\" in name:\n",
    "        return \"pl\"\n",
    "    if \"italian\" in name:\n",
    "        return \"it\"\n",
    "    if \"danish\" in name:\n",
    "        return \"da\"\n",
    "    return \"en\"\n",
    "\n",
    "def compute_toxicity_for_paths(txt_paths: List[Path], lang: str) -> Dict[str, float]:\n",
    "    lex = load_hurtlex(lang)\n",
    "    docs_with_toxic = 0\n",
    "    tokens_total = 0\n",
    "    toxic_tokens_total = 0\n",
    "    for p in txt_paths:\n",
    "        text = read_text(p)\n",
    "        toks = _tokenize(text)\n",
    "        if not toks:\n",
    "            continue\n",
    "        tokens_total += len(toks)\n",
    "        toxic_here = sum(1 for t in toks if t in lex)\n",
    "        toxic_tokens_total += toxic_here\n",
    "        if toxic_here > 0:\n",
    "            docs_with_toxic += 1\n",
    "    toxic_per_1k = (1000.0 * toxic_tokens_total / tokens_total) if tokens_total else 0.0\n",
    "    toxic_doc_rate = (100.0 * docs_with_toxic / len(txt_paths)) if txt_paths else 0.0\n",
    "    return {\n",
    "        \"tox_lang\": lang,\n",
    "        \"toxic_tokens\": float(toxic_tokens_total),\n",
    "        \"toxic_per_1k\": toxic_per_1k,\n",
    "        \"toxic_doc_rate_%\": toxic_doc_rate,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b4c461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of authorship changes: counts `0` and `1` inside JSON structures. By default it counts across all JSON files.\n",
    "\n",
    "def safe_load_json(path: Path) -> Any:\n",
    "    try:\n",
    "        raw = path.read_text(encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        raw = path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "    return json.loads(raw)\n",
    "\n",
    "def count_zero_one_tokens(obj: Any) -> Tuple[int, int]:\n",
    "    zeros = 0\n",
    "    ones = 0\n",
    "    stack = [obj]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        if isinstance(cur, dict):\n",
    "            stack.extend(cur.values())\n",
    "        elif isinstance(cur, list):\n",
    "            stack.extend(cur)\n",
    "        elif isinstance(cur, (int, float)):\n",
    "            if isinstance(cur, bool):\n",
    "                continue\n",
    "            if cur == 0:\n",
    "                zeros += 1\n",
    "            elif cur == 1:\n",
    "                ones += 1\n",
    "        elif COUNT_STRING_TOKENS_TOO and isinstance(cur, str):\n",
    "            if cur == \"0\":\n",
    "                zeros += 1\n",
    "            elif cur == \"1\":\n",
    "                ones += 1\n",
    "    return zeros, ones\n",
    "\n",
    "def compute_json_counts_for_folder(\n",
    "    folder: Path, recursive: bool = True, allowed_stems: Optional[Set[str]] = None\n",
    ") -> Dict[str, int]:\n",
    "    json_files = 0\n",
    "    zeros_total = 0\n",
    "    ones_total = 0\n",
    "    parse_errors = 0\n",
    "    for jpath in iter_json_files(folder, recursive=recursive):\n",
    "        if allowed_stems is not None and jpath.stem not in allowed_stems:\n",
    "            continue\n",
    "        json_files += 1\n",
    "        try:\n",
    "            obj = safe_load_json(jpath)\n",
    "        except Exception:\n",
    "            parse_errors += 1\n",
    "            continue\n",
    "        z, o = count_zero_one_tokens(obj)\n",
    "        zeros_total += z\n",
    "        ones_total += o\n",
    "    return {\n",
    "        \"json_files\": json_files,\n",
    "        \"json_parse_errors\": parse_errors,\n",
    "        \"zeros\": zeros_total,\n",
    "        \"ones\": ones_total,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44684028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots and table reports\n",
    "\n",
    "def pct(z: int, o: int) -> Tuple[float, float]:\n",
    "    total = z + o\n",
    "    if total == 0:\n",
    "        return 0.0, 0.0\n",
    "    return (100.0 * z / total), (100.0 * o / total)\n",
    "\n",
    "def print_report(results: List[Dict[str, Any]]) -> None:\n",
    "    headers = [\n",
    "        \"folder\",\n",
    "        \"txt_files\",\n",
    "        \"avg_sentence_len_words\",\n",
    "        \"min_sentence_len_words\",\n",
    "        \"max_sentence_len_words\",\n",
    "        \"avg_word_len_chars\",\n",
    "        \"min_sentences_per_doc\",\n",
    "        \"max_sentences_per_doc\",\n",
    "        \"avg_sentences_per_doc\",\n",
    "        \"json_files\",\n",
    "        \"json_parse_errors\",\n",
    "        \"zeros\",\n",
    "        \"ones\",\n",
    "        \"zeros_%\",\n",
    "        \"ones_%\",\n",
    "        \"repeated_punct_rate\",\n",
    "        \"all_caps_token_rate\",\n",
    "        \"elongation_rate\",\n",
    "        \"informality_score\",\n",
    "        \"tox_lang\",\n",
    "        \"toxic_tokens\",\n",
    "        \"toxic_per_1k\",\n",
    "        \"toxic_doc_rate_%\",\n",
    "        \"sampled_txt\",\n",
    "    ]\n",
    "    def fmt(v: Any) -> str:\n",
    "        if v is None:\n",
    "            return \"NA\"\n",
    "        if isinstance(v, float):\n",
    "            return f\"{v:.3f}\"\n",
    "        return str(v)\n",
    "    rows = [[fmt(r.get(h)) for h in headers] for r in results]\n",
    "    widths = [max(len(h), *(len(row[i]) for row in rows)) for i, h in enumerate(headers)]\n",
    "    def line(cols):\n",
    "        return \" | \".join(c.ljust(widths[i]) for i, c in enumerate(cols))\n",
    "    print(line(headers))\n",
    "    print(\"-+-\".join(\"-\" * w for w in widths))\n",
    "    for row in rows:\n",
    "        print(line(row))\n",
    "\n",
    "def _filtered_for_plot(results: List[Dict[str, Any]], key: str) -> List[Dict[str, Any]]:\n",
    "    return [r for r in results if float(r.get(key, 0.0) or 0.0) != 0.0]\n",
    "\n",
    "def _distinct_bar_colors(n: int):\n",
    "    cmap = plt.get_cmap(\"tab20\")\n",
    "    return [cmap(i % cmap.N) for i in range(n)]\n",
    "\n",
    "def plot_metric_bar(\n",
    "    results: List[Dict[str, Any]],\n",
    "    outdir: Path,\n",
    "    key: str,\n",
    "    title: str,\n",
    "    ylabel: str,\n",
    "    filename: str,\n",
    ") -> None:\n",
    "    data = _filtered_for_plot(results, key)\n",
    "    if not data:\n",
    "        print(f\"[WARN] No non-zero '{key}' values found; skipping {filename}.\")\n",
    "        return\n",
    "    labels = [r[\"folder_name\"] for r in data]\n",
    "    values = [float(r.get(key, 0.0) or 0.0) for r in data]\n",
    "    x = range(len(labels))\n",
    "    plt.figure(figsize=(max(10, len(labels) * 1.2), 6))\n",
    "    plt.bar(list(x), values, color=_distinct_bar_colors(len(values)))\n",
    "    plt.xticks(list(x), labels, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / filename, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_json_01(results: List[Dict[str, Any]], outdir: Path) -> None:\n",
    "    data = [r for r in results if (r.get(\"zeros\", 0) + r.get(\"ones\", 0)) > 0]\n",
    "    if not data:\n",
    "        print(\"[WARN] No JSON 0/1 tokens found; skipping JSON plots.\")\n",
    "        return\n",
    "    labels = [r[\"folder_name\"] for r in data]\n",
    "    x = range(len(labels))\n",
    "    zeros_pct, ones_pct = [], []\n",
    "    for r in data:\n",
    "        zp, op = pct(r[\"zeros\"], r[\"ones\"])\n",
    "        zeros_pct.append(zp)\n",
    "        ones_pct.append(op)\n",
    "    plt.figure(figsize=(max(10, len(labels) * 1.2), 6))\n",
    "    plt.bar([i - 0.2 for i in x], zeros_pct, width=0.4, label=\"0 %\")\n",
    "    plt.bar([i + 0.2 for i in x], ones_pct, width=0.4, label=\"1 %\")\n",
    "    plt.xticks(list(x), labels, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Percentage (%)\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.title(\"Percentages of 0 vs 1 in the corpora (per folder)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"json_0_vs_1_percentages_per_folder.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_hurtlex_lexicon_sizes(lex_sizes: Dict[str, int], outdir: Path) -> None:\n",
    "    if not lex_sizes:\n",
    "        print(\"[WARN] No HurtLex lexicon sizes provided; skipping HurtLex size plot.\")\n",
    "        return\n",
    "    order = [\"en\", \"it\", \"pl\", \"da\"]\n",
    "    langs = [l for l in order if l in lex_sizes] + [l for l in lex_sizes.keys() if l not in order]\n",
    "    values = [int(lex_sizes[l]) for l in langs]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(langs, values, color=_distinct_bar_colors(len(values)))\n",
    "    plt.xlabel(\"Language\")\n",
    "    plt.ylabel(\"Unique lemmas\")\n",
    "    plt.title(\"HurtLex lexicon sizes (after filters)\")\n",
    "    for i, v in enumerate(values):\n",
    "        plt.text(i, v, str(v), ha=\"center\", va=\"bottom\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"hurtlex_lexicon_sizes_after_filters.png\", dpi=200)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fc7aecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we used this to extract example sentences of specific lengths for error analysis, and a sanity check\n",
    "\n",
    "def sentences_with_word_len_in_file(path: Path, target_len: int, max_examples: int = 25) -> List[str]:\n",
    "    try:\n",
    "        text = read_text(path)\n",
    "    except Exception:\n",
    "        return []\n",
    "    out: List[str] = []\n",
    "    for sent in split_sentences(text):\n",
    "        words = WORD_RE.findall(sent)\n",
    "        if not words:\n",
    "            continue\n",
    "        if len(words) == 1 and words[0].lower() in {\"gt\", \"lt\", \"amp\"}:\n",
    "            continue\n",
    "        if len(words) == target_len:\n",
    "            out.append(sent)\n",
    "            if len(out) >= max_examples:\n",
    "                break\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "283974a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HurtLex lexicon sizes (after filters) ===\n",
      "en: 700 unique lemmas\n",
      "it: 561 unique lemmas\n",
      "pl: 412 unique lemmas\n",
      "da: 242 unique lemmas\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run info on size of HurtLex corpora after filters\n",
    "\n",
    "rng = random.Random(RANDOM_SEED)\n",
    "outdir = Path(\"plots_out\")\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# HurtLex lexicon sizes after filters\n",
    "hurtlex_sizes: Dict[str, int] = {}\n",
    "print(\"\\n=== HurtLex lexicon sizes (after filters) ===\")\n",
    "for lang in [\"en\", \"it\", \"pl\", \"da\"]:\n",
    "    lex = load_hurtlex(lang)\n",
    "    hurtlex_sizes[lang] = len(lex)\n",
    "    print(f\"{lang}: {len(lex)} unique lemmas\")\n",
    "print(\"===========================================\\n\")\n",
    "\n",
    "plot_hurtlex_lexicon_sizes(hurtlex_sizes, outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b959242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder                                        | txt_files | avg_sentence_len_words | min_sentence_len_words | max_sentence_len_words | avg_word_len_chars | min_sentences_per_doc | max_sentences_per_doc | avg_sentences_per_doc | json_files | json_parse_errors | zeros | ones  | zeros_% | ones_% | repeated_punct_rate | all_caps_token_rate | elongation_rate | informality_score | tox_lang | toxic_tokens | toxic_per_1k | toxic_doc_rate_% | sampled_txt\n",
      "----------------------------------------------+-----------+------------------------+------------------------+------------------------+--------------------+-----------------------+-----------------------+-----------------------+------------+-------------------+-------+-------+---------+--------+---------------------+---------------------+-----------------+-------------------+----------+--------------+--------------+------------------+------------\n",
      "reddit_dataset_new_POLISH                     | 250       | 13.102                 | 2.000                  | 152.000                | 5.099              | 4.000                 | 35.000                | 16.664                | 250        | 0                 | 1659  | 2261  | 42.321  | 57.679 | 0.365               | 7.116               | 0.949           | 8.430             | pl       | 105.000      | 1.916        | 30.000           | 250/250    \n",
      "reddit_dataset_new_ITALIAN                    | 250       | 15.499                 | 3.000                  | 195.000                | 4.766              | 4.000                 | 35.000                | 18.864                | 250        | 0                 | 1723  | 2749  | 38.529  | 61.471 | 0.477               | 4.417               | 0.886           | 5.780             | it       | 429.000      | 5.849        | 70.400           | 250/250    \n",
      "reddit_dataset_new_DANISH                     | 250       | 15.037                 | 3.000                  | 125.000                | 4.350              | 4.000                 | 35.000                | 14.584                | 250        | 0                 | 1683  | 1722  | 49.427  | 50.573 | 0.510               | 5.521               | 1.367           | 7.398             | da       | 60.000       | 1.093        | 17.600           | 250/250    \n",
      "pan25-multi-author-analysis/easy/train        | 250       | 17.044                 | 1.000                  | 194.000                | 4.753              | 3.000                 | 30.000                | 12.560                | 4200       | 0                 | 38178 | 10224 | 78.877  | 21.123 | 0.019               | 7.754               | 0.056           | 7.829             | en       | 364.000      | 6.801        | 72.800           | 250/4200   \n",
      "pan25-multi-author-analysis/easy/validation   | 250       | 17.210                 | 1.000                  | 212.000                | 4.738              | 4.000                 | 29.000                | 12.260                | 900        | 0                 | 8046  | 2201  | 78.521  | 21.479 | 0.133               | 9.005               | 0.360           | 9.498             | en       | 379.000      | 7.185        | 71.200           | 250/900    \n",
      "pan25-multi-author-analysis/medium/train      | 250       | 17.952                 | 1.000                  | 146.000                | 4.685              | 4.000                 | 49.000                | 14.584                | 4200       | 0                 | 46314 | 12503 | 78.743  | 21.257 | 0.015               | 7.563               | 0.061           | 7.639             | en       | 412.000      | 6.294        | 68.800           | 250/4200   \n",
      "pan25-multi-author-analysis/medium/validation | 250       | 17.652                 | 1.000                  | 113.000                | 4.692              | 4.000                 | 62.000                | 14.728                | 900        | 0                 | 10009 | 2750  | 78.447  | 21.553 | 0.015               | 6.693               | 0.123           | 6.831             | en       | 389.000      | 5.985        | 66.000           | 250/900    \n",
      "pan25-multi-author-analysis/hard/train        | 250       | 18.496                 | 1.000                  | 89.000                 | 4.635              | 5.000                 | 35.000                | 13.420                | 4200       | 0                 | 42246 | 8815  | 82.736  | 17.264 | 0.016               | 9.347               | 0.081           | 9.444             | en       | 472.000      | 7.606        | 75.200           | 250/4200   \n",
      "pan25-multi-author-analysis/hard/validation   | 250       | 19.281                 | 1.000                  | 115.000                | 4.601              | 3.000                 | 33.000                | 12.824                | 900        | 0                 | 8742  | 1906  | 82.100  | 17.900 | 0.000               | 8.509               | 0.226           | 8.736             | en       | 470.000      | 7.603        | 75.200           | 250/900    \n"
     ]
    }
   ],
   "source": [
    "# run report\n",
    "\n",
    "reddit_folders = [\n",
    "    Path(\"reddit_dataset_new_POLISH\"),\n",
    "    Path(\"reddit_dataset_new_ITALIAN\"),\n",
    "    Path(\"reddit_dataset_new_DANISH\"),\n",
    "]\n",
    "\n",
    "pan_folders = [\n",
    "    PAN_ROOT / \"easy\" / \"train\",\n",
    "    PAN_ROOT / \"easy\" / \"validation\",\n",
    "    PAN_ROOT / \"medium\" / \"train\",\n",
    "    PAN_ROOT / \"medium\" / \"validation\",\n",
    "    PAN_ROOT / \"hard\" / \"train\",\n",
    "    PAN_ROOT / \"hard\" / \"validation\",\n",
    "]\n",
    "\n",
    "all_folders = reddit_folders + pan_folders\n",
    "results: List[Dict[str, Any]] = []\n",
    "\n",
    "for folder in all_folders:\n",
    "    if folder.name in {\"train\", \"validation\"}:\n",
    "        folder_name = f\"{folder.parent.name}/{folder.name}\"\n",
    "    else:\n",
    "        folder_name = folder.name if folder.name else str(folder)\n",
    "    row: Dict[str, Any] = {\"folder\": str(folder), \"folder_name\": folder_name}\n",
    "    if not folder.exists():\n",
    "        row.update(\n",
    "            {\n",
    "                \"txt_files\": 0,\n",
    "                \"sentences\": 0,\n",
    "                \"words\": 0,\n",
    "                \"avg_sentence_len_words\": None,\n",
    "                \"min_sentence_len_words\": None,\n",
    "                \"max_sentence_len_words\": None,\n",
    "                \"avg_word_len_chars\": None,\n",
    "                \"min_sentences_per_doc\": None,\n",
    "                \"max_sentences_per_doc\": None,\n",
    "                \"avg_sentences_per_doc\": None,\n",
    "                \"json_files\": 0,\n",
    "                \"json_parse_errors\": 0,\n",
    "                \"zeros\": 0,\n",
    "                \"ones\": 0,\n",
    "                \"zeros_%\": 0.0,\n",
    "                \"ones_%\": 0.0,\n",
    "                \"repeated_punct_rate\": 0.0,\n",
    "                \"all_caps_token_rate\": 0.0,\n",
    "                \"elongation_rate\": 0.0,\n",
    "                \"informality_score\": 0.0,\n",
    "                \"tox_lang\": detect_language_for_folder(folder),\n",
    "                \"toxic_tokens\": 0.0,\n",
    "                \"toxic_per_1k\": 0.0,\n",
    "                \"toxic_doc_rate_%\": 0.0,\n",
    "                \"sampled_txt\": \"NA\",\n",
    "            }\n",
    "        )\n",
    "        results.append(row)\n",
    "        continue\n",
    "    is_pan_split = PAN_ROOT in folder.parents\n",
    "    sample_n = PAN_SAMPLE_N if is_pan_split else None  # Reddit uses ALL docs\n",
    "    all_txt = list_txt_files(folder)\n",
    "    sampled_txt = choose_sample(all_txt, sample_n=sample_n, rng=rng)\n",
    "    row[\"sampled_txt\"] = f\"{len(sampled_txt)}/{len(all_txt)}\" if all_txt else \"0/0\"\n",
    "    if DEBUG_PAN_DISCOVERY and is_pan_split:\n",
    "        sample_json = next(iter(iter_json_files(folder, recursive=True)), None)\n",
    "        if sample_json is not None:\n",
    "            print(f\"[OK] Found JSON under {folder}: e.g. {sample_json.name}\")\n",
    "        else:\n",
    "            print(f\"[WARN] No JSON found under {folder} (check root/path/nesting)\")\n",
    "        print(f\"[INFO] PAN sampling for {folder_name}: {row['sampled_txt']} (seed={RANDOM_SEED})\")\n",
    "    row.update(compute_text_stats_for_paths(sampled_txt))\n",
    "    row.update(compute_informality_for_paths(sampled_txt))\n",
    "    lang = detect_language_for_folder(folder)\n",
    "    row.update(compute_toxicity_for_paths(sampled_txt, lang=lang))\n",
    "    # JSON authorship changes\n",
    "    allowed_stems = {p.stem for p in sampled_txt} if (JSON_SAMPLE_MATCH_TXT and sampled_txt) else None\n",
    "    row.update(compute_json_counts_for_folder(folder, recursive=True, allowed_stems=allowed_stems))\n",
    "    zp, op = pct(row[\"zeros\"], row[\"ones\"])\n",
    "    row[\"zeros_%\"], row[\"ones_%\"] = zp, op\n",
    "    results.append(row)\n",
    "\n",
    "print_report(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d14966c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAX_SENT_LEN_FILE] reddit_dataset_new_POLISH: problem-239.txt\n",
      "[MIN_SENT_LEN_FILES] reddit_dataset_new_POLISH: problem-150.txt, problem-234.txt\n",
      "[MIN_SENT_LEN_SENTENCES] reddit_dataset_new_POLISH: problem-150.txt (len=2)\n",
      "  - tyle wygraÄ‡ ðŸ† ðŸ‘ðŸ»\n",
      "[MIN_SENT_LEN_SENTENCES] reddit_dataset_new_POLISH: problem-234.txt (len=2)\n",
      "  - Do zobaczenia!\n",
      "[MAX_SENT_LEN_FILE] reddit_dataset_new_ITALIAN: problem-219.txt\n",
      "[MIN_SENT_LEN_FILES] reddit_dataset_new_ITALIAN: problem-100.txt, problem-116.txt\n",
      "[MIN_SENT_LEN_SENTENCES] reddit_dataset_new_ITALIAN: problem-100.txt (len=3)\n",
      "  - I â€œbiâ€ locali ðŸ˜­ðŸ˜­ðŸ˜­\n",
      "[MIN_SENT_LEN_SENTENCES] reddit_dataset_new_ITALIAN: problem-116.txt (len=3)\n",
      "  - Tagli le ruote ðŸ”ª\n",
      "[MAX_SENT_LEN_FILE] reddit_dataset_new_DANISH: problem-208.txt\n",
      "[MIN_SENT_LEN_FILES] reddit_dataset_new_DANISH: problem-103.txt, problem-127.txt\n",
      "[MIN_SENT_LEN_SENTENCES] reddit_dataset_new_DANISH: problem-103.txt (len=3)\n",
      "  - Rigtig flot gjort ðŸ˜ŽðŸ˜ŽðŸ‘\n",
      "[MIN_SENT_LEN_SENTENCES] reddit_dataset_new_DANISH: problem-127.txt (len=3)\n",
      "  - KÃ¸b gamestop aktier.. ðŸ’°ðŸ“ˆðŸš€\n",
      "[MAX_SENT_LEN_FILE] pan25-multi-author-analysis/hard/validation: problem-845.txt\n",
      "[MIN_SENT_LEN_FILES] pan25-multi-author-analysis/hard/validation: problem-423.txt, problem-631.txt\n",
      "[MIN_SENT_LEN_SENTENCES] pan25-multi-author-analysis/hard/validation: problem-423.txt (len=1)\n",
      "  - Yes.\n",
      "[MIN_SENT_LEN_SENTENCES] pan25-multi-author-analysis/hard/validation: problem-631.txt (len=1)\n",
      "  - WTF!\n",
      "  - Indeed.\n"
     ]
    }
   ],
   "source": [
    "# inspecting selected folders to see example sentences of min lengths\n",
    "\n",
    "PRINT_INSPECT_FOLDERS = {\n",
    "    str(Path(\"reddit_dataset_new_POLISH\")),\n",
    "    str(Path(\"reddit_dataset_new_ITALIAN\")),\n",
    "    str(Path(\"reddit_dataset_new_DANISH\")),\n",
    "    str(PAN_ROOT / \"hard\" / \"validation\"),\n",
    "}\n",
    "\n",
    "for r in results:\n",
    "    folder_path = str(r.get(\"folder\", \"\"))\n",
    "    if folder_path not in PRINT_INSPECT_FOLDERS:\n",
    "        continue\n",
    "    max_fname = r.get(\"max_sentence_len_file\")\n",
    "    print(f\"[MAX_SENT_LEN_FILE] {folder_path}: {Path(max_fname).name if max_fname else 'NA'}\")\n",
    "    min_files = r.get(\"min_sentence_len_files\") or []\n",
    "    if not isinstance(min_files, list):\n",
    "        min_files = [str(min_files)]\n",
    "    min_files = [str(x) for x in min_files if x][:2]\n",
    "    print(f\"[MIN_SENT_LEN_FILES] {folder_path}: {', '.join(Path(x).name for x in min_files) if min_files else 'NA'}\")\n",
    "    try:\n",
    "        min_len = int(float(r.get(\"min_sentence_len_words\"))) if r.get(\"min_sentence_len_words\") is not None else None\n",
    "    except Exception:\n",
    "        min_len = None\n",
    "    if min_len is None or not min_files:\n",
    "        print(f\"[MIN_SENT_LEN_SENTENCES] {folder_path}: NA\")\n",
    "        continue\n",
    "    for fp in min_files:\n",
    "        p = Path(fp)\n",
    "        examples = sentences_with_word_len_in_file(p, min_len, max_examples=25)\n",
    "        print(f\"[MIN_SENT_LEN_SENTENCES] {folder_path}: {p.name} (len={min_len})\")\n",
    "        if not examples:\n",
    "            print(\"  - NA\")\n",
    "        else:\n",
    "            for s in examples:\n",
    "                print(f\"  - {s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3d1a1cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the following plots:\n",
      " - json_0_vs_1_percentages_per_folder.png\n",
      " - informality_score_per_folder.png\n",
      " - toxic_words_per_1k_per_folder.png\n",
      " - hurtlex_lexicon_sizes_after_filters.png\n"
     ]
    }
   ],
   "source": [
    "# plots\n",
    "\n",
    "plot_json_01(results, outdir)\n",
    "\n",
    "plot_metric_bar(\n",
    "    results,\n",
    "    outdir,\n",
    "    key=\"informality_score\",\n",
    "    title=\"Informality score (per 1k tokens) by folder\",\n",
    "    ylabel=\"Informality score (per 1k tokens)\",\n",
    "    filename=\"informality_score_per_folder.png\",\n",
    ")\n",
    "\n",
    "plot_metric_bar(\n",
    "    results,\n",
    "    outdir,\n",
    "    key=\"toxic_per_1k\",\n",
    "    title=\"Toxic word rate (HurtLex) per 1k tokens by folder\",\n",
    "    ylabel=\"Toxic words per 1k tokens\",\n",
    "    filename=\"toxic_words_per_1k_per_folder.png\",\n",
    ")\n",
    "\n",
    "print(f\"Saved the following plots:\")\n",
    "print(\" - json_0_vs_1_percentages_per_folder.png\")\n",
    "print(\" - informality_score_per_folder.png\")\n",
    "print(\" - toxic_words_per_1k_per_folder.png\")\n",
    "print(\" - hurtlex_lexicon_sizes_after_filters.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328e56f",
   "metadata": {},
   "source": [
    "### Other analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "02d93963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HurtLex size normalization\n",
      "Reference size (median): 486.5 lemmas\n",
      "  da: 242 lemmas | factor = 2.0103\n",
      "  en: 700 lemmas | factor = 0.6950\n",
      "  it: 561 lemmas | factor = 0.8672\n",
      "  pl: 412 lemmas | factor = 1.1808\n",
      "==========================\n",
      "\n",
      "Saved plot:\n",
      "toxic_words_per_1k_per_folder_normalized.png\n"
     ]
    }
   ],
   "source": [
    "# here we normalize the toxic word rates by HurtLex lexicon sizes\n",
    "\n",
    "try:\n",
    "    hurtlex_sizes\n",
    "except NameError:\n",
    "    hurtlex_sizes = {}\n",
    "    for _lang in [\"en\", \"it\", \"pl\", \"da\"]:\n",
    "        hurtlex_sizes[_lang] = len(load_hurtlex(_lang))\n",
    "\n",
    "_sizes = [v for v in hurtlex_sizes.values() if isinstance(v, int) and v > 0]\n",
    "if not _sizes:\n",
    "    raise ValueError(\"No HurtLex sizes available--- cannot normalize.\")\n",
    "_sizes_sorted = sorted(_sizes)\n",
    "_mid = len(_sizes_sorted) // 2\n",
    "ref_size = float(_sizes_sorted[_mid]) if (len(_sizes_sorted) % 2 == 1) else float((_sizes_sorted[_mid - 1] + _sizes_sorted[_mid]) / 2)\n",
    "\n",
    "print(\"HurtLex size normalization\")\n",
    "print(f\"Reference size (median): {ref_size:.1f} lemmas\")\n",
    "for _lang, _sz in sorted(hurtlex_sizes.items()):\n",
    "    if _sz > 0:\n",
    "        print(f\"  {_lang}: {_sz} lemmas | factor = {ref_size / _sz:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {_lang}: {_sz} lemmas | factor = NA\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "for r in results:\n",
    "    lang = (r.get(\"tox_lang\") or \"en\").lower()\n",
    "    lex_sz = hurtlex_sizes.get(lang, 0)\n",
    "    tox = float(r.get(\"toxic_per_1k\") or 0.0)\n",
    "    factor = (ref_size / lex_sz) if lex_sz else 1.0\n",
    "    r[\"toxic_per_1k_lexnorm\"] = tox * factor\n",
    "\n",
    "plot_metric_bar(\n",
    "    results,\n",
    "    outdir,\n",
    "    key=\"toxic_per_1k_lexnorm\",\n",
    "    title=\"Toxic word rate (HurtLex) per 1k tokens by folder (lexicon-size normalized)\",\n",
    "    ylabel=\"Toxic words per 1k tokens (lexicon-size normalized)\",\n",
    "    filename=\"toxic_words_per_1k_per_folder_normalized.png\",\n",
    ")\n",
    "\n",
    "print(\"Saved plot:\")\n",
    "print(\"toxic_words_per_1k_per_folder_normalized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "84342683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in PAN folders\n",
      "Target phrases:\n",
      " - Debate/discuss/argue the merits of ideas, don't attack people.\n",
      " - I am a bot, and this action was performed automatically.\n",
      "\n",
      "easy/train: 563 matched documents\n",
      "easy/validation: 133 matched documents\n",
      "medium/train: 2305 matched documents\n",
      "medium/validation: 510 matched documents\n",
      "hard/train: 13 matched documents\n",
      "hard/validation: 2 matched documents\n"
     ]
    }
   ],
   "source": [
    "# analyzing and detecting the amount of bot-generated phrases or community rules that repeat in the datasets\n",
    "# doing this only for PAN datasets here\n",
    "\n",
    "TARGET_BOT_PHRASES = (\n",
    "    \"Debate/discuss/argue the merits of ideas, don't attack people.\",\n",
    "    \"I am a bot, and this action was performed automatically.\",\n",
    ")\n",
    "\n",
    "PAN_FOLDERS = [\n",
    "    PAN_ROOT / \"easy\" / \"train\",\n",
    "    PAN_ROOT / \"easy\" / \"validation\",\n",
    "    PAN_ROOT / \"medium\" / \"train\",\n",
    "    PAN_ROOT / \"medium\" / \"validation\",\n",
    "    PAN_ROOT / \"hard\" / \"train\",\n",
    "    PAN_ROOT / \"hard\" / \"validation\",\n",
    "]\n",
    "\n",
    "def read_text_utf8(path: Path) -> str:\n",
    "    try:\n",
    "        return path.read_text(encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "\n",
    "def find_matching_txt_files(folder: Path, phrases: tuple[str, ...]) -> list[Path]:\n",
    "    if not folder.exists():\n",
    "        return []\n",
    "    matched: list[Path] = []\n",
    "    for path in folder.rglob(\"*.txt\"):\n",
    "        if not path.is_file():\n",
    "            continue\n",
    "        text = read_text_utf8(path)\n",
    "        if any(phrase in text for phrase in phrases):\n",
    "            matched.append(path)\n",
    "    return sorted(matched)\n",
    "\n",
    "print(\"Results in PAN folders\")\n",
    "print(\"Target phrases:\")\n",
    "for phrase in TARGET_BOT_PHRASES:\n",
    "    print(f\" - {phrase}\")\n",
    "print()\n",
    "\n",
    "for folder in PAN_FOLDERS:\n",
    "    folder_disp = f\"{folder.parent.name}/{folder.name}\"  # e.g., easy/train\n",
    "    matched = find_matching_txt_files(folder, TARGET_BOT_PHRASES)\n",
    "    print(f\"{folder_disp}: {len(matched)} matched documents\")\n",
    "    # for path in matched:\n",
    "    #    print(f\"  - {path.name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
