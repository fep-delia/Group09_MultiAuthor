{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21ec351-464d-4a30-b550-d8221c133091",
   "metadata": {},
   "source": [
    "# Language Adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c9e35-722a-4245-87ae-dc5947b85942",
   "metadata": {},
   "source": [
    "## Plug in model and add adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831a541-b12a-4647-b727-24628851b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adapters\n",
    "from adapters import AdapterModelInterface\n",
    "from transformers import AutoModelForMaskedLM\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98575a27-66d7-4ea1-9aa0-073ae5c7620e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Based on: https://github.com/adapter-hub/adapters/blob/main/src/adapters/wrappers/interfaces.py\n",
    "\n",
    "plugin_interface = AdapterModelInterface(\n",
    "    adapter_methods=[\"bottleneck\", \"invertible\"], #Enable all bottleneck (task) and invertible (lang)\n",
    "    model_embeddings=\"embeddings\",\n",
    "    model_layers=\"layers\",\n",
    "    layer_self_attn=\"attn\",\n",
    "    layer_cross_attn=None,\n",
    "    attn_qkv_proj=\"Wqkv\",\n",
    "    attn_o_proj=\"Wo\",\n",
    "    layer_intermediate_proj=\"mlp.Wi\",\n",
    "    layer_output_proj=\"mlp.Wo\",\n",
    "    layer_pre_self_attn=\"attn\",\n",
    "    layer_pre_cross_attn=None,\n",
    "    layer_pre_ffn=\"mlp\",\n",
    "    layer_ln_1=\"mlp_norm\",\n",
    "    layer_ln_2=None,\n",
    ")\n",
    "\n",
    "#Load model and plug it in\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"jhu-clsp/mmBERT-base\")\n",
    "adapters.init(model, interface=plugin_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf206ef-4165-4c58-b811-b1f08a802e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import SeqBnInvConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfece18-d9a0-4372-861b-19e48eee5838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On this link: https://docs.adapterhub.ml/training.html, they show that they train language adapters on \"seq_bn_inv\", so we do that too. Name of config can be found here: https://docs.adapterhub.ml/overview.html\n",
    "config = SeqBnInvConfig()\n",
    "model.add_adapter(\"English_adapter_2\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671d2ed-ebf5-4aee-b1c7-763fdd7648ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.adapter_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f719a0-4640-49bb-8d6d-71d78d877a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_adapters(\"English_adapter_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12d29f-540b-4fe3-8dcc-c37c51c13051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_adapter(\"English_adapter_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94617f0e-d40b-41d2-849c-60a5b7ef9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_adapter(\"English_adapter_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a1743-4f16-4671-8c81-bafb14409bda",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d571a6f4-c6fe-4b95-b64d-ffb7239bf721",
   "metadata": {},
   "source": [
    "The language adapters trained by the authors of the library are trained on Wikipedia articles. So, we also do that, using the Wikimedia Hugging Face dataset \\\n",
    "Every instance (e.g. dataset['train'][0]) is a whole article. Find out whether to make them shorter\n",
    "\n",
    "Reference:\n",
    "https://huggingface.co/docs/datasets/use_dataset - shows how to extract the text we want from each datapoint (here we want the text-columns and don't care about title- or url-columns) and get them tokenized. \n",
    "    \n",
    "Next, we want to concatenate the dataset and split it anew to get chunks that are readable by the model. Then, we mask them using Hugging Face's pipeline. Link: https://huggingface.co/docs/transformers/main/tasks/masked_language_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbaf49e-9050-45e2-8441-c177340f5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bf383-cac4-4a1e-ba55-852a68f4512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"jhu-clsp/mmBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1fcfb-239d-4c57-82d5-e26b4547ebae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This dataset only has 1 split, \"train\", no \"test\"\n",
    "ds = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\", split = 'train[:10000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee4420-5789-43b2-9972-701a4eaba928",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\", split = 'train[10000:12000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec1ab9-0525-48ba-9938-a5b75ad7227a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3cceae-7c2e-44b3-bd27-557d9658f522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(ds[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770eb7a-5084-4188-9f51-a3603b552c6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer(ds[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c158c1c-02d4-4d5e-810a-8784a37f751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b8c79-d7ba-44bf-8b90-85c598d3a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to video on https://huggingface.co/docs/transformers/main/tasks/masked_language_modeling, this is a good way of chunking when our inputs are very long\n",
    "def tokenize_and_chunk(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=1024, #Smaller than the model's max size to save memory. Try 1024, faster + lower loss\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    result = {\n",
    "    'input_ids': [],\n",
    "    'attention_mask': [],\n",
    "    }\n",
    "\n",
    "    for i in range(len(tokenized[\"input_ids\"])):\n",
    "        if tokenized[\"length\"][i] < 100:\n",
    "            continue\n",
    "        result[\"input_ids\"].append(tokenized[\"input_ids\"][i])\n",
    "        result[\"attention_mask\"].append(tokenized[\"attention_mask\"][i])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc990c-6d7a-49cd-96f3-e7e860b3a911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batched = ds.map(tokenize_and_chunk, batched = True, remove_columns = ['id', 'url', 'title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00d995-febf-442a-a86d-0bf542944bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batched = ds1.map(tokenize_and_chunk, batched = True, remove_columns = ['id', 'url', 'title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fbaaac-9656-4a0a-909c-8b9292f6ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched #This should altsÃ¥ work. There are 4006 rows, so more than the number of articles.\n",
    "#Every row is 2048 long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4cfa8-1319-476f-b79d-54be340ea4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched.set_format(type ='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60b53f-6104-4458-b5e8-d23ce9926afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batched.set_format(type ='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da454e8-cc6d-45eb-b2e6-a2fda658818b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batched[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7955831-2a4c-40fa-b721-015654e4b8a2",
   "metadata": {},
   "source": [
    "## Train adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a2ed2-43ba-4ff2-917b-9cc204720cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The adapter trainer does take a collate function: https://docs.adapterhub.ml/classes/adapter_training.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff01f9c-856a-4379-848c-7de6ce669674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777873f-d7e4-4be2-86d9-1edea0471b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a6be9-fce1-4099-88eb-66e891b0313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on Github code and https://docs.adapterhub.ml/training.html\n",
    "\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, EvalPrediction\n",
    "from adapters import AdapterTrainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate= 1e-4, #it is a higher rate and should converge faster\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=16, #Compute gradient for batches of 16\n",
    "    #gradient_checkpointing=True, #Saves memory but makes training slower\n",
    "    logging_steps=200,\n",
    "    output_dir=\"./training_output_English_2\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c39d9-75fb-45f2-b1f3-ef09ecababcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_batched,\n",
    "    eval_dataset=test_batched,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec82969-047d-4991-be59-82872c7c9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = trainer.get_train_dataloader()\n",
    "batch = next(iter(test))\n",
    "\n",
    "print(batch.keys())\n",
    "print(batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437e66e-ea62-430d-a3bd-ad047ab87453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3734342-151a-4d41-b2dc-4e1174781494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_adapter(\"./English_adapter_loss_20.57\", \"English_adapter_2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
